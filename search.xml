<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>学期小结&amp;寒假计划</title>
      <link href="/2024/01/23/%E5%AD%A6%E6%9C%9F%E5%B0%8F%E7%BB%93&amp;%E5%AF%92%E5%81%87%E8%AE%A1%E5%88%92/"/>
      <url>/2024/01/23/%E5%AD%A6%E6%9C%9F%E5%B0%8F%E7%BB%93&amp;%E5%AF%92%E5%81%87%E8%AE%A1%E5%88%92/</url>
      
        <content type="html"><![CDATA[<blockquote><p>自上次更新博客，已是很久，唯一一次更新还是更的图形学作业。之前还想着说记录记录自己的学习。但由于学业压力太大，临近期末，太多大作业以及要复习，实在是没时间写博客。</p></blockquote><h1 id="学期小结"><a href="#学期小结" class="headerlink" title="学期小结"></a>学期小结</h1><p>在大三上开学前，我去清华参加了它的图形学启明星计划的夏令营。大抵是出于运气，我被选上参加了。与我一同参加夏令营的同学真的都很优秀，每一个都感觉对图形学都很多的研究，我的一个室友，感觉更是厉害，似乎已经是在进行科研的项目了。这给我带了还算是蛮大的打击。我一直都处于中大计院的井底中，不知外界的同学们水平如何。几个关系好的高中同学也不是学习计算机的。自己看着自己的绩点排名，也是自我满足。参加完夏令营，我回到学校，心里就想着一定要搞搞科研，好好努力，弥补下自己与其他同学的差距。</p><p>回到中大，我联系了自己实验室的师兄。从games101开始逐步的学习，跟着网上的一些博客做了games101的作业。然后跟着师兄的研究兴趣，开始好好地看NeRF。大二下也算是看了一点点，但真的不是很认真。（我最开始进入HCP实验室，最主要的是想要个工位，可以固定的来读书学习，不用每天去图书馆找位子hh）后面开始看HumanNeRF，在chatGPT的帮助下，也算是基本理解了作者的思路。接下来，就是看HumanNeRF的代码，复现作者的结果。其实复现不算太难，作者已经在github上非常详细地教我们怎么去运行，终端的命令都已经给出来了。但是，其代码是真的难以理解。中大计院是不教python的，我之前也只有在人工智能实验课上用python写了点简单的作业，只用到了python最基础的语法。但是HumanNeRF里面涉及很多numpy以及pytorch的语法，我完全看不懂。看的着实艰难，没办法，硬着头皮，我把代码抛给chatGPT，在它地帮助下，我打断点，一行一行的看。大概是了解了代码的框架。那段时间我基本每天都呆在实验室到夜里11点，每天都充满了绝望，感叹自己的弱小。常常盯着屏幕，一看一下午，完全不知道怎么理解代码。毫无进展，感觉纯纯地浪费人生。在这里，我真的很感谢我的妈妈。那些天，我晚上走出实验室，已经没有共享单车。我就和妈妈打电话，走回寝室。她不断的鼓励我，让我踏实下来，一步一个脚印。同时，我也很感谢自己的一位同学，一次我遇到一个难题，想着他也在搞科研。请求他的帮助，他果断同意，我把电脑带到他寝室，与我一起debug到12:30。现在，回想起来，自己是幸运的，有这么好的父母以及伙伴们。</p><p>再谈课内学习，这学期我本人的感觉是自己真的努力了很多。大概是由于大二下的期末考烂了，排名跌了不少，内心有所不甘，想着这学期努努力，提高一下排名。这几天，已经出了几门成绩了。之前还担心期末周发烧会考差，结果考的还算是满意。努力还是有回报的。</p><p>这学期还有一个突破，我参加了计院的院运会。之前，我是从未参加过运动会的。这学期，我跟着一个同学跑了跑步，他鼓励我参加400米，我也就报名了。最后，竟然得了第8名的成绩，真的蛮开心。算是我人生中第一个关于运动的奖项。</p><p><img src="https://xiao10ma.github.io/images/diary/IMG_2686.HEIC" alt=""></p><h1 id="寒假计划"><a href="#寒假计划" class="headerlink" title="寒假计划"></a>寒假计划</h1><p>寒假已经放了10天。说句实话，我这几天每天摆烂，在家里刷手机，无所事事。感觉实在是内心有愧，浪费人生。不能这样下去。特于此，写下一篇博客。也算是一种监督自己的方式，计划从今天起每天坚持学习（除去未来过几日的外出旅行），也会更新博客（记录一下所学所感）。若是哪天，我摆烂了，那天便不会有博客的更新。希望是不会的哈哈。</p><p>此时此刻，已经是晚上21:26分。计划稍后学学3D gaussian splatting，白天已经看了一会。这个真的太厉害了，对于NeRF而言真是降维打击，训练和渲染效率真是高了太多。最近，也是有很多论文的提出。卷卷卷！！</p><p>好，就写到这里吧。寒假也要开始好好努力了。最后感谢这个学期努力的自己，努力终有所回报。</p>]]></content>
      
      
      <categories>
          
          <category> 日记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 日记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CG 大作业</title>
      <link href="/2024/01/02/CGreport/"/>
      <url>/2024/01/02/CGreport/</url>
      
        <content type="html"><![CDATA[<h1 id="CG大作业"><a href="#CG大作业" class="headerlink" title="CG大作业"></a>CG大作业</h1><h2 id="内容"><a href="#内容" class="headerlink" title="内容"></a>内容</h2><p>成员：马梓培 李涛 熊蔚然</p><p>我们选取交互这个选题，想复现出⼀款游戏，“火柴人打羽毛球”。本地双人对打。</p><p>我们最终实现的效果：</p><ol><li>控制火柴人的移动，包括左移右移，向上跳跃。以及击打羽毛球</li><li>根据球拍的角度，去实现对击打羽毛球的模拟，包括球速以及角度</li><li>背后场馆观众，可以通过纹理贴图实现</li></ol><p>以下是网络上一些游戏的截图：</p><p><img src="https://xiao10ma.github.io/images/CGreport/d52d002f6ed648d88815065dea9916ac.png" alt="Alt text"></p><h3 id="1-火柴人控制原理"><a href="#1-火柴人控制原理" class="headerlink" title="1 火柴人控制原理"></a>1 火柴人控制原理</h3><p>我是基于“GAMES105-计算机角色动画基础”课程，来建模以及控制火柴人动作的。</p><p><strong>关节的种类</strong></p><div align = "center">    <img src="https://xiao10ma.github.io/images/CGreport/image.png"></div><p>因为实现的是二维平面的运动，所以关节的自由度为1，只会在一个平面上进行顺时针or逆时针的旋转。</p><p><strong>前向运动学</strong></p><p>从根节点往叶结点乘变换矩阵</p><ul><li>朝向：关节的局部坐标系相对于世界坐标系的旋转</li><li>旋转矩阵的逆就是旋转矩阵的转置： 正交矩阵的性质</li></ul><div align = "center">    <img src="https://xiao10ma.github.io/images/CGreport/image-1.png"></div><p>某一个关节处的全局旋转矩阵 = 父关节旋转矩阵 * 该关节的局部旋转矩阵</p><div align = "center">    <img src="https://xiao10ma.github.io/images/CGreport/image-2.png"></div><h3 id="2-火柴人建模（蓝色为关节）："><a href="#2-火柴人建模（蓝色为关节）：" class="headerlink" title="2 火柴人建模（蓝色为关节）："></a>2 火柴人建模（蓝色为关节）：</h3><div align = "center">    <img src="https://xiao10ma.github.io/images/CGreport/image-5.png"width="300"></div><p>举例来说，左手臂小臂的全局旋转矩阵 = 左手臂大臂的全局旋转矩阵 <em> 左手臂小臂的局部旋转矩阵；右小腿的全局旋转矩阵 = 右大腿的全局旋转矩阵 </em> 右小腿的局部旋转矩阵……</p><p>在具体实现时，通过glPushMatrix()，先把当前的矩阵压入栈中，然后进行旋转，最后通过glPopMatrix()，把当前矩阵弹出栈，恢复到之前的状态。</p><p>部分代码实现：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">glPushMatrix</span>();     <span class="comment">// ArmA</span></span><br><span class="line"><span class="built_in">glRotatef</span>(armA, <span class="number">0.f</span>, <span class="number">0.f</span>, <span class="number">1.f</span>);</span><br><span class="line"><span class="built_in">glPushMatrix</span>();     <span class="comment">// ArmB</span></span><br><span class="line"><span class="built_in">glTranslatef</span>(<span class="number">24.f</span>, <span class="number">-2.f</span>, <span class="number">0.f</span>);</span><br><span class="line"><span class="built_in">glRotatef</span>(armB, <span class="number">0.f</span>, <span class="number">0.f</span>, <span class="number">1.f</span>);</span><br><span class="line"><span class="built_in">drawArmB</span>();</span><br><span class="line"><span class="built_in">glPopMatrix</span>();      <span class="comment">// ArmB</span></span><br><span class="line"><span class="built_in">drawArmA</span>();</span><br><span class="line"><span class="built_in">glPopMatrix</span>();      <span class="comment">// ArmA</span></span><br></pre></td></tr></table></figure><p>这里的实现中，ArmA表示大臂，ArmB表示小臂。</p><p>例如，我们想要小臂进行旋转，需要先将大臂的旋转矩阵压入栈中。在此基础之上，才能进行小臂的局部旋转。小臂是依托于大臂的，两者之间存在一定耦合性。</p><h4 id="2-1-移动"><a href="#2-1-移动" class="headerlink" title="2.1 移动"></a>2.1 移动</h4><p>由建模直接画出，但是关节间是存在依赖关系的。</p><p>左移、右移，我模拟了人走路的姿势：</p><p><img src="https://xiao10ma.github.io/images/CGreport/%E7%A7%BB%E5%8A%A8.gif" alt="Alt text"></p><p>可以看到，正是小腿基于大腿的旋转，最后的移动是自然的，符合人类走路的方式。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">right_legA = -legA_angle_vec[index];</span><br><span class="line">right_legB = -legB_angle_vec[index];</span><br><span class="line">left_legA = legA_angle_vec[index];</span><br><span class="line">index = (++index) % <span class="number">5</span>;</span><br></pre></td></tr></table></figure><p>具体实现时，因为人的走路姿势是循环的，我构造了两个数组，分别表示大腿和小腿的旋转角度。通过 <code>index = (++index) % 5</code>来更新下标，达到循环遍历数组的效果。这里我为了游戏的流畅性，将循环的频率设置为5，因此最后的人物移动可能看起来是会有点间断，不连续。</p><h4 id="2-2-跳跃"><a href="#2-2-跳跃" class="headerlink" title="2.2 跳跃"></a>2.2 跳跃</h4><p>火柴人的跳跃，我结合了物理学建模。</p><p>实时垂直方向速度：</p><script type="math/tex; mode=display">cur\_v_{y} = pre\_v_{y} - gt</script><p>实时垂直方向位置：</p><script type="math/tex; mode=display">cur\_position_y = pre\_position_y + pre\_v_y * timeSinceJump - \frac{1}{2}gt^2</script><p>这里时间 <code>t</code>的获取我是通过调用 <code>&lt;chrono&gt;</code>这个库来实现的。首先，先定义一个 <code>Common.cpp</code>源文件，定义startTime变量</p><p><code>std::chrono::steady_clock::time_point startTime = std::chrono::steady_clock::now();</code></p><p>因此，startTime变量在程序开始运行时就被定义了。在其他文件中，我们可以一样使用 <code>&lt;chrono&gt;</code>库获得当前时间，再用extern引用startTime，两者相减，便可以知道程序运行的时间。出于方便，我又定义了一个 <code>Common.h</code>头文件，用 <code>extern</code>引用startTime。其他文件直接 <code>include &#39;Common.h&#39;</code>即可，不需要重复extern。</p><p>因此，当我们想实现跳跃时。我们需要知道两个关于时间的变量，分别是跳跃起始时间，当前时间。当前时间-跳跃起始时间，便是跳跃时间。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// myglWideget.cpp</span></span><br><span class="line"><span class="built_in">doubleGetCurrentTimeInSeconds</span>() &#123;</span><br><span class="line">    usingnamespacestd::chrono;</span><br><span class="line"></span><br><span class="line">    returnduration_cast&lt;duration&lt;<span class="type">double</span>&gt;&gt;(steady_clock::<span class="built_in">now</span>() - startTime).<span class="built_in">count</span>();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">player1-&gt;jumpStartTime = <span class="built_in">GetCurrentTimeInSeconds</span>();</span><br><span class="line"></span><br><span class="line">-----------------------------------------------------------------------------------</span><br><span class="line"></span><br><span class="line"><span class="comment">//player.cppp</span></span><br><span class="line"><span class="type">float</span> currentTime = <span class="built_in">playerGetCurrentTimeInSeconds</span>();</span><br><span class="line"><span class="type">float</span> timeSinceJump = currentTime - jumpStartTime;</span><br><span class="line"></span><br><span class="line">jumpHeight = jumpVelocity * timeSinceJump - <span class="number">0.5f</span> * GRAVITY * timeSinceJump * timeSinceJump;</span><br><span class="line">right_legB = <span class="number">-20.f</span>;</span><br><span class="line"><span class="keyword">if</span> (jumpHeight &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">    isJumping = <span class="literal">false</span>;</span><br><span class="line">    jumpHeight = <span class="number">0</span>; </span><br><span class="line">    right_legB = <span class="number">0.f</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://xiao10ma.github.io/images/CGreport/%E8%B7%B3%E8%B7%83.gif" alt="Alt text"></p><h4 id="2-3-挥拍"><a href="#2-3-挥拍" class="headerlink" title="2.3 挥拍"></a>2.3 挥拍</h4><p>挥拍的实现，和上面的思路基本一致。唯一不同的是，手臂旋转的角度，通过$sin(\theta)$实现，其中$\theta$属于[0,180]度。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (timeSinceWave &gt; <span class="number">0.5</span>) &#123;</span><br><span class="line">    isWaving = <span class="literal">false</span>;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line">arm = <span class="number">-135</span> * <span class="built_in">sin</span>(<span class="number">2</span> * PI * timeSinceWave);</span><br><span class="line">armA = <span class="number">-100</span> * <span class="built_in">sin</span>(<span class="number">2</span> * PI * timeSinceWave);</span><br></pre></td></tr></table></figure><p>-135和-100度，分别是持拍的手臂和大臂的旋转角度。</p><p>另外，我还建模了发球时人物的挥拍，具体实现原理类似。</p><p><img src="https://xiao10ma.github.io/images/CGreport/12.gif" alt="Alt text"></p><h3 id="3-羽毛球运动建模"><a href="#3-羽毛球运动建模" class="headerlink" title="3 羽毛球运动建模"></a>3 羽毛球运动建模</h3><h4 id="3-1-球速"><a href="#3-1-球速" class="headerlink" title="3.1 球速"></a>3.1 球速</h4><p><img src="https://xiao10ma.github.io/images/CGreport/image-6.png" alt="Alt text"></p><p>建模击打羽毛球后，羽毛球的旋转角度，以及速度大小。</p><p>$|v_{球}| = |v_{球}|+|v_{拍}|+k\theta-C$</p><p>击打回羽毛球后，羽毛球的球速等于当前羽毛球的球速+固定拍子动能+拍子旋转角度-羽毛球球拍吸收的动能。</p><p>这是对羽毛球运动的一个简单的建模，并且符合现实。随着拍子旋转角度越大，对羽毛球速度的提升越大。对应于$k\theta$。并且羽毛球拍会吸收固定的动能，对应于$-C$。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">float</span> cur_bmt_speed = <span class="built_in">sqrt</span>(curspeed_x * curspeed_x + curspeed_y * curspeed_y);</span><br><span class="line">cur_bmt_speed += <span class="number">2.f</span> * theta - <span class="number">100.f</span> + <span class="number">110.f</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (whohit == <span class="number">1</span>) &#123;</span><br><span class="line">    curspeed_x = cur_bmt_speed * <span class="built_in">cos</span>((<span class="number">60</span> - theta) * PI / <span class="number">180.f</span>);</span><br><span class="line">    curspeed_y = cur_bmt_speed * <span class="built_in">sin</span>((<span class="number">60</span> - theta) * PI / <span class="number">180.f</span>);</span><br><span class="line">    prespeed_x = curspeed_x;</span><br><span class="line">    prespeed_y = curspeed_y;</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">elseif</span> (whohit == <span class="number">2</span>) &#123;</span><br><span class="line">    curspeed_x = -cur_bmt_speed * <span class="built_in">cos</span>((<span class="number">60</span> - theta) * PI / <span class="number">180.f</span>);</span><br><span class="line">    curspeed_y = cur_bmt_speed * <span class="built_in">sin</span>((<span class="number">60</span> - theta) * PI / <span class="number">180.f</span>);</span><br><span class="line">    prespeed_x = curspeed_x;</span><br><span class="line">    prespeed_y = curspeed_y;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="3-2-球速更新"><a href="#3-2-球速更新" class="headerlink" title="3.2 球速更新"></a>3.2 球速更新</h4><p>飞行时，通过这两个公式更新球速：</p><script type="math/tex; mode=display">cur\_speed_{x} = pre\_speed_{x} - FRICTION * timeSinceHit</script><script type="math/tex; mode=display">cur\_speed_{y} = pre\_speed_{y} - GRAVITY * timeSinceHit</script><p>对应羽毛球的角度，通过反正切函数来获得。</p><p>实现代码</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">curposition_x = preposition_x + timeSinceHit * curspeed_x;</span><br><span class="line">curposition_y = preposition_y + prespeed_y * timeSinceHit - <span class="number">0.5</span> * GRAVITY * timeSinceHit * timeSinceHit;</span><br><span class="line">curspeed_y = prespeed_y - GRAVITY * timeSinceHit;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (prespeed_x - FRICTION * timeSinceHit &gt; <span class="number">0</span>)</span><br><span class="line">    curspeed_x = prespeed_x - FRICTION * timeSinceHit;</span><br><span class="line"><span class="keyword">if</span> (whohit == <span class="number">1</span>)</span><br><span class="line">    angle = <span class="number">90</span> + <span class="built_in">atan</span>(curspeed_y / curspeed_x) * rad_to_deg;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    angle = <span class="number">-90</span> + <span class="built_in">atan</span>(curspeed_y / curspeed_x) * rad_to_deg;</span><br></pre></td></tr></table></figure><p><strong>羽毛球检测击中</strong></p><p>根据球拍的全局旋转矩阵获得当前时刻的球拍的中心坐标，判断羽毛球当前时刻的位置是否与球拍中心位置接近。只要两者的距离小于设定的阈值，便视为击中。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">float</span> racket_global_angle = player1-&gt;arm + <span class="number">135</span>;</span><br><span class="line"><span class="type">float</span> d_x = (<span class="number">30.f</span> + <span class="number">40.f</span> * <span class="built_in">sqrt</span>(<span class="number">2.</span>)) * <span class="built_in">cos</span>(racket_global_angle / <span class="number">180</span> * PI);</span><br><span class="line"><span class="type">float</span> d_y = (<span class="number">30.f</span> + <span class="number">40.f</span> * <span class="built_in">sqrt</span>(<span class="number">2.</span>)) * <span class="built_in">sin</span>(racket_global_angle / <span class="number">180</span> * PI);</span><br><span class="line"></span><br><span class="line"><span class="type">float</span> cur_center_x = player1-&gt;position_x + (<span class="type">float</span>)(<span class="number">95.0</span> / <span class="number">120</span> * <span class="number">10</span>) + d_x;</span><br><span class="line"><span class="type">float</span> cur_center_y = <span class="number">95.f</span> + d_y;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (badminton-&gt;curposition_x &gt;= cur_center_x - bounding_box_size &amp;&amp; badminton-&gt;curposition_x &lt;= cur_center_x + bounding_box_size &amp;&amp; badminton-&gt;curposition_y &gt;= cur_center_y - bounding_box_size &amp;&amp; cur_center_y + bounding_box_size &gt;= badminton-&gt;curposition_y) &#123;</span><br><span class="line">    return1;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>最终的效果：</p><p><img src="https://xiao10ma.github.io/images/CGreport/击球.gif" alt="Alt text"></p><h2 id="实验总结"><a href="#实验总结" class="headerlink" title="实验总结"></a>实验总结</h2><p>这个大作业，还是蛮有意思的。它设计到了方方面面。包括物理，数学的建模，以及人物运动时，身体各个关节处的耦合性。我是学习了Games105后才对其有了浅薄的理解。从头到尾，我们的大作业都是100%原创的（至少我的部分是），这还是蛮有挑战的。所幸，在老师的建议和同学的帮助下（深夜一起debug，感谢我的好homie 李涛），我们最终完成了这个大作业。我的收获也是颇丰，虽然火柴人的建模很简单，但是我对前向运动学知识的理解加深了很多。父关节和子关节之间的联系，是很关键的，这是让火柴人动起来的重要因素！！</p>]]></content>
      
      
      <categories>
          
          <category> CG </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CG </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>NeRF 笔记</title>
      <link href="/2023/11/16/nerfreport/"/>
      <url>/2023/11/16/nerfreport/</url>
      
        <content type="html"><![CDATA[<h1 id="NeRF-笔记"><a href="#NeRF-笔记" class="headerlink" title="NeRF 笔记"></a>NeRF 笔记</h1><blockquote><p>写在前面<br>这原是我图形学课上论文阅读的一个作业，现放在自己博客里面，也当是我学习NeRF的一个小结。</p></blockquote><h2 id="NeRF"><a href="#NeRF" class="headerlink" title="NeRF"></a>NeRF</h2><h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><p>NeRF提出了一种通过使用输入视图的稀疏集来优化底层连续体积场景函数，进而实现复杂场景的新视图合成的最先进的结果的方法。使用全连接（非卷积）深度网络，输入有五个维度（空间坐标$(x,y,z)$，视角方向$(\theta,\phi)$），输出是该空间位置的体积密度$\sigma$和视角相关的color。再通过传统的体渲染技术得到最后的像素值。通过比较生成图像和ground truth作为loss，来训练神经网络。</p><h3 id="NeRF的意义是什么？"><a href="#NeRF的意义是什么？" class="headerlink" title="NeRF的意义是什么？"></a>NeRF的意义是什么？</h3><p>经典的图形学渲染流程中，我们是通过对输入的图像进行三维建模，再去进行自由视角的渲染。这就要求构建出非常高质量的三维模型才能渲染出精细的结果。但是很多情况下，三维模型的构建是比较困难的。但是NeRF基于深度学习的流程，通过对三维场景的神经表达，结合可微分渲染，可以实现端到端的训练。最终可以实现在任意视角下对模型的渲染。</p><h3 id="NeRF的基本原理"><a href="#NeRF的基本原理" class="headerlink" title="NeRF的基本原理"></a>NeRF的基本原理</h3><p>NeRF的流程基本上可以用这幅图概括：<br><img src="https://xiao10ma.github.io/images/NeRF/image.png" alt="经典 NeRF 流程图"></p><ol><li><p>沿着相机光线，采样5D坐标合成图像 (位置和观看方向)</p><p>通过$r(t) = o + td$确定光线，沿着该光线得到采样点，$r_i=r(t_i)$</p></li><li><p>将这些输入MLP以产生颜色和体积密度</p><p>将采样点的三维坐标$(x, y, z)$和相机的视角$(\theta, \phi)$作为输入，得到$\sigma$和RGB值。</p></li><li><p>使用传统体渲染技术将这些值计算为最终的RGB值</p><p>$\begin{aligned} \hat{C}(\mathbf{r}) &amp; =\sum_{i=1}^N T_i\left(1-\exp \left(-\sigma_i \delta_i\right)\right) \mathbf{c}_i, \\ T_i &amp; =\exp \left(-\sum_{j=1}^{i-1} \sigma_j \delta_j\right)\end{aligned}$</p></li><li><p>通过最小化合成图像和真实图像之间的loss来优化我们的场景表示</p><p>$\mathcal{L}=\sum_{\mathbf{r} \in \mathcal{R}}|\hat{C}(\mathbf{r})-C(\mathbf{r})|_2^2$</p></li></ol><h3 id="NeRF的一些优化"><a href="#NeRF的一些优化" class="headerlink" title="NeRF的一些优化"></a>NeRF的一些优化</h3><ol><li><p>位置编码</p><p>尽管神经网络是通用的函数近似器, 但作者发现, 让网络 $F \Theta$ 直接操作 $x y z \theta \varphi$ 输入坐标会导致渲染在表示颜色和几何形状方面的高频变化方面表现不佳。这与Rahaman最近的工作是一致的,这表明深度网络偏向于学习低频函数。他们还表明, 在将输入传递给网络之前, 使用高频函数将输入映射到更高维度的空间, 可以更好地拟合包含高频变化的数据。</p></li><li><p>View Dependence</p><p>这是基础图形学中的知识，高光依赖于视角的方向。</p></li><li><p>分层采样</p><p>利用第一次采样点预测的密度值确定第二次采样点的位置，可以减少计算的开销，同时也需要改变下体渲染公式<br>$\mathcal{L}=\sum_{\mathbf{r} \in \mathcal{R}}\left[\left|\hat{C}_c(\mathbf{r})-C(\mathbf{r})\right|_2^2+\left|\hat{C}_f(\mathbf{r})-C(\mathbf{r})\right|_2^2\right]$</p></li></ol><p>以上1，2点的举例：<br><img src="https://xiao10ma.github.io/images/NeRF/image-1.png" alt=""></p><h3 id="NeRF的局限性"><a href="#NeRF的局限性" class="headerlink" title="NeRF的局限性"></a>NeRF的局限性</h3><ol><li>最初时的NeRF计算效率比较低，训练时间长。目前，有一些模型的改善，包括instant-ngp（哈希编码）,3D Gaussian Splatting（高斯核）。目前，3D Gaussian Splatting的效果很不错，对毛发的重建很逼真！！</li><li>无法进行泛化，一个神经网络只适用于一个模型。要是想再重建模型，只能重新训练。</li><li>无法重建动态的场景</li></ol><h2 id="HumanNeRF"><a href="#HumanNeRF" class="headerlink" title="HumanNeRF"></a>HumanNeRF</h2><h3 id="Abstract-1"><a href="#Abstract-1" class="headerlink" title="Abstract"></a>Abstract</h3><p>作者介绍了一种名为“Hu-manNeRF”的自由视点渲染方法。这种方法可以应用于单目摄像头拍摄的视频，例如YouTube上的视频，其中人物进行复杂的身体动作。其核心功能是允许在视频的任何一帧暂停，然后从任意新的摄像机视角渲染主体，甚至可以为那个特定的帧和身体姿势创建一个完整的360度摄像机路径。</p><p>这项任务特别具有挑战性，因为它需要合成从各种可能在输入视频中不存在的摄像机角度看到的身体的逼真细节，以及合成如衣服褶皱和面部外观等细微之处。</p><p>该方法通过优化人物在规范的T型姿势中的体积表示，以及与之配合的运动场，将估计的规范表示映射到视频的每一帧，通过后向扭曲实现。运动场被分解为骨骼的刚性运动和非刚性运动，这些运动由深度网络产生。</p><p>研究表明，与之前的工作相比，这种方法在性能上有显著的提升，并且在未受控制的捕捉场景中，展示了从单目视频中移动人物的自由视点渲染的引人入胜的例子。</p><h3 id="HumanNeRF的基本原理"><a href="#HumanNeRF的基本原理" class="headerlink" title="HumanNeRF的基本原理"></a>HumanNeRF的基本原理</h3><p>HumanNeRF的流程基本上可以用这幅图还有一个公式概括：<br><img src="https://xiao10ma.github.io/images/NeRF/image-2.png" alt=""></p><blockquote><p>We represent a moving person with a canonical appearance volume $F_c$ warped to an observed pose to produce output appearance volume $F_o$ :</p><script type="math/tex; mode=display">F_o(\mathbf{x}, \mathbf{p})=F_c(T(\mathbf{x}, \mathbf{p})),</script><p>where $F_c: \mathbf{x} \rightarrow(\mathbf{c}, \sigma)$ maps position $\mathbf{x}$ to color $\mathbf{c}$ and density $\sigma$, and $T:\left(\mathbf{x}_o, \mathbf{p}\right) \rightarrow \mathbf{x}_c$ defines a motion field mapping points from observed space back to canonical space, guided by observed pose $\mathbf{p}=(J, \Omega)$, where $J$ includes $K$ standard 3D joint locations, and $\Omega=\left\{\boldsymbol{\omega}_i\right\}$ are local joint rotations represented as axis-angle vectors $\boldsymbol{\omega}_i$.</p></blockquote><p>我先来讲下这个公式</p><p>$T:\left(\mathbf{x}_o, \mathbf{p}\right) \rightarrow \mathbf{x}_c$这个函数将observation space（观察空间）的点和当前估计的人体pose，映射回canonical space（标准空间）的点。函数$F_c$以标准空间的点作为输入，输出color和$\sigma$。可以看到，这里其实是和传统的NeRF不同的。正如我上面所说，传统的NeRF是有5维的输入，而HumanNeRF却少了$(\theta, \phi)$。这也正是HumanNeRF的一个缺陷，即只能考虑漫反射。</p><p>再来讲讲流程图</p><p>与NeRF一样，相机发出一条射线，再采样。但是作者这里思想非常巧妙。作者运用上面的公式，将观察空间中采样的点映射回标准空间中，从标准空间中采样。有几点好处：</p><ol><li><strong>姿态不变性</strong>：通过将观察空间中的点映射到标准空间，可以将人体的不同姿态统一到一个标准化的参考姿态。这样做有助于模型更好地学习和理解人体的三维结构，而不是专注于特定的姿态或视角。</li><li><strong>数据一致性</strong>：在标准空间中处理数据可以确保不同图像或观察中的相同身体部位被一致地表示，这对于训练神经网络来说是非常重要的。这种一致性有助于网络更有效地学习和泛化。</li><li><strong>简化学习任务</strong>：将复杂的人体动态映射到一个静态的、标准化的空间，可以简化学习任务。网络不需要同时处理人体的动态变化和外观变化，而是可以专注于从标准化的视角学习人体的外观。</li><li><strong>更好的泛化能力</strong>：通过这种映射，模型可以更好地泛化到新的姿态和视角，因为它学习的是从标准化姿态到实际观察姿态的映射。这对于实际应用中的灵活性和鲁棒性是非常重要的。</li><li><strong>高效的渲染</strong>：在标准空间中进行渲染计算可以提高效率，因为可以重用对于不同观察视角相同的计算结果，而不是针对每个新视角重新计算整个场景。</li></ol><p>observation space的点映射到标准空间，作者将$T(x,p)$拆分成两部分：$T(\mathbf{x}, \mathbf{p})=T_{\text {skel }}(\mathbf{x}, \mathbf{p})+T_{\mathrm{NR}}\left(T_{\text {skel }}(\mathbf{x}, \mathbf{p}), \mathbf{p}\right)$。即骨骼和非骨骼两部分。骨骼的部分，正如其名，即为骨骼的映射。非骨骼部分，包括毛发、衣服，这些柔软的材料。</p><p>$T_{\text {skel }}(\mathbf{x}, \mathbf{p})=\sum_{i=1}^K w_o^i(\mathbf{x})\left(R_i \mathbf{x}+\mathbf{t}_i\right)$<br>刚体骨骼这里通过逆LBS实现，LBS具体实现可以参照games105(Lecture7)。逆即为从T-pose到observation pose。</p><p>$T_{\mathrm{NR}}(\mathbf{x}, \mathbf{p})=\operatorname{MLP}_{\theta_{\mathrm{NR}}}(\gamma(\mathbf{x}) ; \Omega)$<br>非骨骼这里通过MLP预测。</p><p>综上所述，HumanNeRF就是从单目摄像头出发，射出光线。在光线中采用，将采样点映射到标准空间中的点。再把标准空间的点输入神经网络，得到其$\sigma$和RGB。最后用体渲染的方式得到最后的像素值。</p><h3 id="自己跑的一些结果"><a href="#自己跑的一些结果" class="headerlink" title="自己跑的一些结果"></a>自己跑的一些结果</h3><p><img src="https://xiao10ma.github.io/images/NeRF/000026.png" alt=""><br><img src="https://xiao10ma.github.io/images/NeRF/000056.png" alt=""><br><img src="https://xiao10ma.github.io/images/NeRF/000083.png" alt=""></p><h3 id="HumanNeRF的局限性"><a href="#HumanNeRF的局限性" class="headerlink" title="HumanNeRF的局限性"></a>HumanNeRF的局限性</h3><p>HumanNeRF对于novel pose不能泛化，其原因是HumanNeRF将Observation space 映射到 canonical space 过拟合了。MonoHuman修正了这个问题。<br>HumanNeRF可能会产生类似于米其林轮胎人的效果（应用新的人体pose）：<br><img src="https://xiao10ma.github.io/images/NeRF/000047.png" alt=""></p><h2 id="MonoHuman"><a href="#MonoHuman" class="headerlink" title="MonoHuman"></a>MonoHuman</h2><blockquote><p>由于变形场是两个不同的多层感知器（MLP），并且依赖于帧或姿态，它们仍然面临过拟合问题。受上述工作的启发，我们设计了我们的共享双向变形模块，使用定义在规范空间中的相同运动权重进行前向和后向变形。</p></blockquote><p>MonoHuman主要的实现，引入$\mathbf{L}_{\text {consis }}$:</p><p>In order to add the constraint that only related to the deformation field as a regularization, we use the intuition of consistency of forward and backward deformation, the consistent loss $\mathbf{L}_{\text {consis }}$ is computed as:</p><script type="math/tex; mode=display">L_{\text {consis }}=\left\{\begin{array}{ll}d & \text { if } d \geq \theta \\0 & \text { else }\end{array} d=L_2\left(\mathbf{x}_{\mathbf{o}}, D_f\left(D_b\left(\mathbf{x}_{\mathbf{o}}, \mathbf{p}\right), \mathbf{p}\right)\right),\right.</script><p>where $L_2$ means the $L_2$ distance calculation, and it only penalize the points whose $L_2$ distance is greater than threshold $\theta$ we set to avoid over regularization.</p><ol><li><strong>前向和后向变形的一致性直觉</strong>：这意味着变形应该是可逆的。例如，如果你首先应用一个变形，然后应用其逆变形，理论上你应该回到原始状态。</li><li><p><strong>一致性损失 $\mathbf{L}_{\text {consis }}$</strong>：这是一个用来衡量变形前后一致性的损失函数。它的计算方式如下：</p><p>$L_{\text {consis }}=\left\{\begin{array}{ll}d &amp; \text { if } d \geq \theta \\ 0 &amp; \text { else }\end{array} d=L_2\left(\mathbf{x}_{\mathbf{o}}, D_f\left(D_b\left(\mathbf{x}_{\mathbf{o}}, \mathbf{p}\right), \mathbf{p}\right)\right)\right.$</p><p>其中 d 是通过以下方式计算的：</p><p>$d=L_2\left(\mathbf{x}_{\mathbf{o}}, D_f\left(D_b\left(\mathbf{x}_{\mathbf{o}}, \mathbf{p}\right), \mathbf{p}\right)\right)$</p><p>这里，$x_o$ 表示原始点，$D_f$ 和 $D_b$ 分别表示前向和后向变形函数，$p$ 表示相关参数。</p></li><li><strong>$L_2$距离计算</strong>：这是一种计算两点之间距离的方法。在这个上下文中，它用于计算变形前后点的距离。</li><li><strong>阈值$\theta$</strong>：这是一个设定的阈值，用于决定何时对点进行惩罚。如果点的$L_2$距离大于这个阈值，它将被纳入损失计算中；如果小于这个阈值，则不会。这样做的目的是为了避免过度正则化，即只对那些变形效果不佳的点施加惩罚。</li></ol><p>这是作者的一个结果，但是我运行的结果一般般，甚至感觉不如HumanNeRF</p><p><img src="https://xiao10ma.github.io/images/NeRF/backflip.gif" alt=""></p><p><a href="https://github.com/Yzmblog/MonoHuman">MonoHuman GitHub链接</a></p>]]></content>
      
      
      <categories>
          
          <category> NeRF </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CG </tag>
            
            <tag> NeRF </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>my first blog</title>
      <link href="/2023/11/15/my-first-blog/"/>
      <url>/2023/11/15/my-first-blog/</url>
      
        <content type="html"><![CDATA[<h1 id="第一次在自己的网站上写blog"><a href="#第一次在自己的网站上写blog" class="headerlink" title="第一次在自己的网站上写blog"></a>第一次在自己的网站上写blog</h1><p>前几日，见识一些佬的网站，看着是真的很帅很酷，我想着自己也要搞一个玩玩看。写来试试。以后就要常更博客，变得更厉害hhh</p><p>花了好久才稍微弄的好看些了，以后再慢慢学习吧</p><p>今天就到这里了，跑步去了</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">abs</span>(<span class="params">x</span>):</span><br><span class="line"><span class="keyword">return</span> <span class="number">1</span></span><br><span class="line"><span class="keyword">if</span> <span class="string">&#x27;__name__&#x27;</span> == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">fff</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 日记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 日记 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
